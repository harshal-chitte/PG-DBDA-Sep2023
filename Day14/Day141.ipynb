{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1b106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd72363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cfb162",
   "metadata": {},
   "source": [
    "# 1. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf5de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "text=\"Hello there, how are you doing today? The weather is great today. The sky is blue. Python is awesome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84c39c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello there, how are you doing today?', 'The weather is great today.', 'The sky is blue.', 'Python is awesome']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89dfd312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'there', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', 'today', '.', 'The', 'sky', 'is', 'blue', '.', 'Python', 'is', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23685813",
   "metadata": {},
   "source": [
    "# 2. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff5ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22def376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vishal',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'boy',\n",
       " '.',\n",
       " 'He',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'in',\n",
       " 'coding',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To remove stopwords for a particular text\n",
    "from nltk.corpus import stopwords\n",
    "text = 'Vishal is a good boy. He is very good in coding.'\n",
    "text = word_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ecad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vishal', 'good', 'boy', '.', 'He', 'good', 'coding', '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_without_stopword = [word for word in text if word not in stopwords.words('english')]\n",
    "text_without_stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791b479",
   "metadata": {},
   "source": [
    "# 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e3bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earn\n",
      "earn\n",
      "earn\n",
      "earn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "example_word = ['earn',\"earning\",\"earned\",\"earns\"]\n",
    "\n",
    "for w in example_word:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17e64b",
   "metadata": {},
   "source": [
    "# 4. Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52b354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c01df0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history\n",
      "formality\n",
      "change\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "example_word=['history','formality','changes']\n",
    "for w in example_word:\n",
    "    print(lemmatizer.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8015b6",
   "metadata": {},
   "source": [
    "# 5. WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c156b099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'felicitous', 'well-chosen', 'glad', 'happy'}\n",
      "{'unhappy'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "for syn in wordnet.synsets(\"happy\"):\n",
    "    for i in syn.lemmas():\n",
    "        synonyms.append(i.name())\n",
    "        if i.antonyms():\n",
    "            antonyms.append(i.antonyms()[0].name())\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8204a",
   "metadata": {},
   "source": [
    "# 6. Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bbd4c0d",
   "metadata": {},
   "source": [
    "### Part of Speech Tag List\n",
    "\n",
    " CC coordinating conjunction\n",
    " CD cardinal digit\n",
    " DT determiner\n",
    " EX existential there (like: “there is” … think of it like “there”)\n",
    " FW foreign word\n",
    " IN preposition/subordinating conjunction\n",
    " JJ adjective ‘big’\n",
    " JJR adjective, comparative ‘bigger’\n",
    " JJS adjective, superlative ‘biggest’\n",
    " LS list marker 1)\n",
    " MD modal could, will\n",
    " NN noun, singular ‘desk’\n",
    " NNS noun plural ‘desks’\n",
    " NNP proper noun, singular ‘Harrison’\n",
    " NNPS proper noun, plural ‘Americans’\n",
    " PDT predeterminer ‘all the kids’\n",
    " POS possessive ending parent’s\n",
    " PRP personal pronoun I, he, she\n",
    " PRP possessive pronoun my, his, hers\n",
    " RB adverb very, silently,\n",
    " RBR adverb, comparative better\n",
    " RBS adverb, superlative best\n",
    " RP particle give up\n",
    " TO to go ‘to’ the store.\n",
    " UH interjection errrrrrrrm\n",
    " VB verb, base form take\n",
    " VBD verb, past tense took\n",
    " VBG verb, gerund/present participle taking\n",
    " VBN verb, past participle taken\n",
    " VBP verb, sing. present, non-3d take\n",
    " VBZ verb, 3rd person sing. present takes\n",
    " WDT wh-determiner which\n",
    " WP wh-pronoun who, what\n",
    " WP possessive wh-pronoun whose\n",
    " WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa25dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae3baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = '''\n",
    "An sincerity so extremity he additions. Her yet there truth merit. Mrs all projecting favourable now unpleasing. Son law garden chatty temper. Oh children provided to mr elegance marriage strongly. Off can admiration prosperous now devonshire diminution law.\n",
    "'''\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71cedf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('An', 'DT'), ('sincerity', 'NN'), ('so', 'RB'), ('extremity', 'NN'), ('he', 'PRP'), ('additions', 'VBZ'), ('.', '.'), ('Her', 'PRP$'), ('yet', 'RB'), ('there', 'EX'), ('truth', 'NN'), ('merit', 'NN'), ('.', '.'), ('Mrs', 'NNP'), ('all', 'DT'), ('projecting', 'VBG'), ('favourable', 'JJ'), ('now', 'RB'), ('unpleasing', 'VBG'), ('.', '.'), ('Son', 'NNP'), ('law', 'NN'), ('garden', 'NN'), ('chatty', 'JJ'), ('temper', 'NN'), ('.', '.'), ('Oh', 'UH'), ('children', 'NNS'), ('provided', 'VBD'), ('to', 'TO'), ('mr', 'VB'), ('elegance', 'NN'), ('marriage', 'NN'), ('strongly', 'RB'), ('.', '.'), ('Off', 'CC'), ('can', 'MD'), ('admiration', 'VB'), ('prosperous', 'JJ'), ('now', 'RB'), ('devonshire', 'VBP'), ('diminution', 'NN'), ('law', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222077f",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3890b4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he is a good boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she is a good girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boy and girl are good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text\n",
       "0       he is a good boy\n",
       "1     she is a good girl\n",
       "2  boy and girl are good"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sent = pd.DataFrame(['he is a good boy', 'she is a good girl', 'boy and girl are good'],columns=['text'])\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84ec484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good boy', 'good girl', 'boy girl good']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in range(0,3):\n",
    "    words = sent['text'][i]\n",
    "    words = word_tokenize(words)\n",
    "    texts = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    text = ' '.join(texts)\n",
    "    corpus.append(text)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc536a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff51ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
